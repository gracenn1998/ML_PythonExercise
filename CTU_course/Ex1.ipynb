{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "strange-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advisory-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_of_2_examples(u, v, q=1):\n",
    "    d_power = np.power(np.abs(np.subtract(u, v)), q)\n",
    "    distance = np.power(np.sum(d_power, axis=0), 1/q)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "limiting-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_of_1set_1ex(set1, ex, q=1):\n",
    "    m = set1.shape[0]\n",
    "    d_set = np.zeros((m, 1))\n",
    "    for i in range(m):\n",
    "        d_set[i] = distance_of_2_examples(set1[i], ex, q)\n",
    "    d_set.reshape(m, 1)\n",
    "    return d_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "persistent-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "def load_dataset(train_set_file_name, test_set_file_name):\n",
    "        \n",
    "    train_set = np.loadtxt(train_set_file_name, delimiter=',')\n",
    "    test_set = np.loadtxt( test_set_file_name, delimiter=',')\n",
    "    \n",
    "    dims = np.size(train_set, 1) - 1 #number of col - 1 = dim, last col is class label\n",
    "    max_class = int(np.amax(train_set[:, dims])) #max value of label\n",
    "   \n",
    "    train_x = train_set[:, :dims]\n",
    "    train_y = train_set[:, -1:]\n",
    "    test_x = test_set[:, :dims]\n",
    "    test_y = test_set[:, -1:]\n",
    "    \n",
    "    #if test_y == -1 => class = -1 vs 1 => let it become 0 - 1 for generalization\n",
    "    #replace -1 -> 0\n",
    "    train_y = np.where(train_y==-1.0, 0, train_y)\n",
    "    test_y = np.where(test_y==-1.0, 0, test_y)\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y, max_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "touched-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_idx(arr, k):\n",
    "    return np.argpartition(arr, -k)[-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "executed-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predict, test_y):\n",
    "    isCorrect = []\n",
    "    isCorrect = (test_y == predict)\n",
    "    correct_cnt = np.count_nonzero(isCorrect==True)\n",
    "    total_cnt = isCorrect.shape[0]\n",
    "    \n",
    "    acc = correct_cnt/total_cnt\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consistent-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predict, test_y, classes):\n",
    "    matrix = np.zeros((classes+1, classes+1)) #matrix[i][j] = predicted j for actual lable i\n",
    "    for i in range(classes+1):\n",
    "        #list of idx where actual label = i\n",
    "        idx = np.where(test_y==i)\n",
    "        for j in range(classes+1):\n",
    "            matrix[i][j] = int(np.count_nonzero(predict[idx]==j))\n",
    "    return matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "retained-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(train_set_file_name, test_set_file_name, k):\n",
    "    #get dataset\n",
    "    train_x, train_y, test_x, test_y, max_class = load_dataset(train_set_file_name, test_set_file_name)\n",
    "    \n",
    "    #get dataset size\n",
    "    m_train = train_x.shape[0]\n",
    "    m_test = test_x.shape[0]\n",
    "    \n",
    "    \n",
    "    d_set = np.zeros((m_test, m_train)) #distance of  ith example in test compare to all examples in train\n",
    "    d_set_top_k_idx = np.zeros((m_test, k), dtype=int) #top k index of k nearest examples\n",
    "    class_of_top_knn = np.zeros((m_test, k), dtype=int) \n",
    "    class_occurence = np.zeros((m_test, max_class+1), dtype=int) #o[i][j]: occurence of class j in ith example\n",
    "    predict = np.zeros((m_test, 1), dtype=int)\n",
    "    \n",
    "    #get top k classes\n",
    "    for i in range(m_test):\n",
    "        #get distance of ith example in test compare to all examples in train\n",
    "        #each row is a list of distance compare to each example in train\n",
    "        d_set[i] = distance_of_1set_1ex(train_x, test_x[i]).reshape(1,-1)\n",
    "        \n",
    "        #sort to get k min distance\n",
    "        #idx = np.argpartition(x, -k)[-k:]  # Indices of top k max, idx not sorted\n",
    "        d_set_top_k_idx[i] = np.argpartition(d_set[i], k)[:k]\n",
    "        \n",
    "        #get ith example's class list of top knn\n",
    "        class_of_top_knn[i] = train_y[d_set_top_k_idx[i]].reshape(1,-1)\n",
    "        \n",
    "        #get class with highest occurence = predict result\n",
    "        for j in range(max_class+1):\n",
    "            class_occurence[i][j] = np.sum(class_of_top_knn[i]==j)\n",
    "        \n",
    "        #predicted class is the class with hight occurence\n",
    "        most_occurence_class = np.squeeze(np.where(class_occurence[i]==np.max(class_occurence[i])))\n",
    "        if most_occurence_class.size==1:\n",
    "            predict[i] = most_occurence_class\n",
    "        else:\n",
    "            #get a random class if many classes have same occurence\n",
    "            predict[i] = np.random.choice(most_occurence_class)\n",
    "#         print(i)\n",
    "#         print(np.where(class_occurence[i]==np.max(class_occurence[i])))\n",
    "#         print(most_occurence_class)\n",
    "#         print( predict[i])\n",
    "    acc = accuracy(predict, test_y)\n",
    "    confusion_arr = confusion_matrix(predict, test_y, max_class)\n",
    "    print(\"Accuracy: \" + str(acc*100) + \"%\")\n",
    "    \n",
    "    print(\"Confusion matrix (col header is actual val, row header is predicted val): \")\n",
    "    label_list = [str(i) for i in range(max_class+1)]\n",
    "    df = pd.DataFrame.from_records(data=confusion_arr, index=label_list)\n",
    "    print(df)\n",
    "    \n",
    "    return predict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "contained-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.0%\n",
      "Confusion matrix (col header is actual val, row header is predicted val): \n",
      "      0     1     2\n",
      "0  17.0   0.0   0.0\n",
      "1   0.0  15.0   0.0\n",
      "2   0.0   4.0  14.0\n",
      "==============\n",
      "Accuracy: 78.75%\n",
      "Confusion matrix (col header is actual val, row header is predicted val): \n",
      "     0     1    2     3    4    5    6     7     8    9    10    11   12   13  \\\n",
      "0   0.0   0.0  0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  0.0   \n",
      "1   0.0  29.0  0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  0.0   \n",
      "2   0.0   0.0  4.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  0.0   \n",
      "3   0.0   1.0  0.0  10.0  0.0  0.0  0.0   1.0   0.0  0.0  0.0   0.0  0.0  0.0   \n",
      "4   0.0   1.0  0.0   0.0  4.0  0.0  0.0   1.0   0.0  0.0  0.0   0.0  1.0  0.0   \n",
      "5   0.0   1.0  0.0   0.0  0.0  8.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  0.0   \n",
      "6   0.0  10.0  0.0   0.0  0.0  0.0  3.0   0.0   0.0  0.0  0.0   1.0  0.0  0.0   \n",
      "7   0.0   0.0  0.0   0.0  0.0  0.0  0.0  10.0   0.0  0.0  0.0   0.0  0.0  0.0   \n",
      "8   0.0   0.0  0.0   0.0  0.0  0.0  0.0   0.0  10.0  0.0  0.0   1.0  0.0  0.0   \n",
      "9   0.0   0.0  0.0   0.0  0.0  0.0  0.0   0.0   0.0  4.0  0.0   3.0  0.0  0.0   \n",
      "10  0.0   0.0  0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  4.0   0.0  0.0  0.0   \n",
      "11  0.0   0.0  0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  10.0  0.0  0.0   \n",
      "12  0.0   1.0  0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  8.0  0.0   \n",
      "13  0.0   1.0  0.0   0.0  0.0  0.0  0.0   1.0   0.0  0.0  0.0   1.0  2.0  5.0   \n",
      "14  0.0   3.0  0.0   0.0  0.0  0.0  0.0   1.0   0.0  0.0  0.0   1.0  1.0  0.0   \n",
      "15  0.0   1.0  0.0   0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  0.0   \n",
      "\n",
      "     14    15  \n",
      "0   0.0   0.0  \n",
      "1   0.0   0.0  \n",
      "2   0.0   0.0  \n",
      "3   0.0   0.0  \n",
      "4   0.0   0.0  \n",
      "5   0.0   0.0  \n",
      "6   0.0   0.0  \n",
      "7   0.0   0.0  \n",
      "8   0.0   0.0  \n",
      "9   0.0   0.0  \n",
      "10  0.0   0.0  \n",
      "11  0.0   0.0  \n",
      "12  0.0   0.0  \n",
      "13  0.0   0.0  \n",
      "14  4.0   0.0  \n",
      "15  0.0  13.0  \n",
      "==============\n",
      "Accuracy: 94.14941494149414%\n",
      "Confusion matrix (col header is actual val, row header is predicted val): \n",
      "       0      1      2      3      4      5      6      7      8      9   ...  \\\n",
      "0   271.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
      "1     0.0  224.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    1.0  ...   \n",
      "2     0.0    0.0  214.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0  ...   \n",
      "3     0.0    1.0    0.0  264.0    0.0    0.0    0.0    9.0    0.0    0.0  ...   \n",
      "4     0.0    3.0    3.0    0.0  228.0    0.0    5.0    1.0    0.0    0.0  ...   \n",
      "5     0.0    0.0    0.0    0.0    0.0  246.0    1.0    1.0    0.0    0.0  ...   \n",
      "6     0.0    3.0    1.0    2.0    4.0    0.0  243.0    1.0    0.0    0.0  ...   \n",
      "7     0.0    1.0    0.0    5.0    2.0    0.0    3.0  198.0    0.0    0.0  ...   \n",
      "8     0.0    1.0    0.0    0.0    0.0    4.0    0.0    0.0  250.0   13.0  ...   \n",
      "9     0.0    0.0    0.0    0.0    2.0    0.0    0.0    1.0    8.0  226.0  ...   \n",
      "10    0.0    2.0    0.0    0.0    0.0    0.0    0.0    6.0    0.0    0.0  ...   \n",
      "11    0.0    0.0    0.0    0.0    3.0    0.0    0.0    1.0    0.0    1.0  ...   \n",
      "12    0.0    2.0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0  ...   \n",
      "13    1.0    2.0    0.0    2.0    0.0    0.0    0.0    2.0    0.0    1.0  ...   \n",
      "14    0.0    0.0    2.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0  ...   \n",
      "15    0.0    1.0    0.0    1.0    1.0   17.0    0.0    2.0    0.0    0.0  ...   \n",
      "16    0.0    0.0    1.0    2.0    0.0    0.0    2.0    0.0    0.0    0.0  ...   \n",
      "17    0.0    1.0    1.0    1.0    0.0    1.0    0.0    6.0    0.0    0.0  ...   \n",
      "18    0.0    1.0    0.0    1.0    1.0    2.0    0.0    0.0    0.0    0.0  ...   \n",
      "19    0.0    1.0    0.0    2.0    0.0    1.0    0.0    0.0    1.0    0.0  ...   \n",
      "20    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  ...   \n",
      "21    0.0    3.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0  ...   \n",
      "22    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0  ...   \n",
      "23    0.0    2.0    0.0    1.0    5.0    0.0    0.0    2.0    0.0    0.0  ...   \n",
      "24    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
      "25    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    1.0  ...   \n",
      "\n",
      "       16     17     18     19     20     21     22     23     24     25  \n",
      "0     0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    1.0    0.0  \n",
      "1     0.0    3.0    3.0    0.0    0.0    3.0    0.0    0.0    0.0    0.0  \n",
      "2     1.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    1.0    0.0  \n",
      "3     0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
      "4     2.0    1.0    0.0    2.0    0.0    0.0    0.0    3.0    0.0   10.0  \n",
      "5     0.0    0.0    1.0    4.0    0.0    1.0    0.0    0.0    1.0    0.0  \n",
      "6     2.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0  \n",
      "7     1.0    6.0    0.0    0.0    1.0    0.0    1.0    1.0    1.0    0.0  \n",
      "8     0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
      "9     1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  \n",
      "10    0.0    6.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
      "11    1.0    3.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
      "12    0.0    1.0    0.0    0.0    0.0    2.0    2.0    0.0    0.0    0.0  \n",
      "13    0.0    4.0    0.0    0.0    1.0    6.0    0.0    0.0    0.0    0.0  \n",
      "14    2.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
      "15    1.0    1.0    1.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0  \n",
      "16  266.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0  \n",
      "17    0.0  252.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
      "18    0.0    1.0  253.0    0.0    1.0    0.0    0.0    2.0    0.0    2.0  \n",
      "19    1.0    0.0    0.0  234.0    0.0    0.0    0.0    0.0    3.0    0.0  \n",
      "20    0.0    0.0    0.0    0.0  270.0    0.0    1.0    0.0    0.0    0.0  \n",
      "21    0.0    1.0    0.0    0.0    1.0  228.0    2.0    0.0    0.0    0.0  \n",
      "22    0.0    0.0    0.0    0.0    0.0    1.0  236.0    0.0    0.0    0.0  \n",
      "23    0.0    1.0    0.0    1.0    2.0    0.0    0.0  244.0    0.0    0.0  \n",
      "24    0.0    0.0    0.0    2.0    1.0    1.0    0.0    1.0  243.0    0.0  \n",
      "25    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  252.0  \n",
      "\n",
      "[26 rows x 26 columns]\n",
      "==============\n",
      "Accuracy: 96.99499165275459%\n",
      "Confusion matrix (col header is actual val, row header is predicted val): \n",
      "       0      1      2      3      4      5      6      7      8      9\n",
      "0  178.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "1    0.0  182.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0\n",
      "2    0.0    4.0  171.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0\n",
      "3    0.0    0.0    0.0  176.0    0.0    2.0    0.0    2.0    3.0    0.0\n",
      "4    0.0    3.0    0.0    0.0  176.0    0.0    0.0    0.0    1.0    1.0\n",
      "5    0.0    0.0    0.0    0.0    1.0  179.0    0.0    0.0    0.0    2.0\n",
      "6    2.0    0.0    0.0    0.0    0.0    0.0  179.0    0.0    0.0    0.0\n",
      "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0  172.0    2.0    5.0\n",
      "8    0.0   10.0    1.0    2.0    0.0    0.0    1.0    0.0  158.0    2.0\n",
      "9    0.0    1.0    0.0    2.0    0.0    4.0    0.0    0.0    1.0  172.0\n",
      "==============\n",
      "Accuracy: 85.29411764705883%\n",
      "Confusion matrix (col header is actual val, row header is predicted val): \n",
      "     0     1\n",
      "0  9.0   5.0\n",
      "1  0.0  20.0\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "predict = {}\n",
    "predict[\"iris\"] = kNN('dataset/iris.trn', 'dataset/iris.tst', k)\n",
    "print(\"==============\")\n",
    "predict[\"fp\"] = kNN('dataset/fp.trn', 'dataset/fp.tst', k)\n",
    "print(\"==============\")\n",
    "predict[\"letter\"]= kNN('dataset/let.trn', 'dataset/let.tst', k)\n",
    "print(\"==============\")\n",
    "predict[\"optics\"]= kNN('dataset/opt.trn', 'dataset/opt.tst', k)\n",
    "print(\"==============\")\n",
    "predict[\"leukemia\"]= kNN('dataset/ALLAML.trn', 'dataset/ALLAML.tst', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-witch",
   "metadata": {},
   "source": [
    "==============================\n",
    "below is testing cell, meaningless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_x, train_y, test_x, test_y, classes = load_dataset('dataset/iris.trn', 'dataset/iris.tst')\n",
    "predict = kNN('dataset/iris.trn', 'dataset/iris.tst', k)\n",
    "idx = np.where(test_y==2)\n",
    "print(idx)\n",
    "print(predict[idx])\n",
    "np.count_nonzero(predict[idx]==1)\n",
    "\n",
    "np.arange(0, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# col_title = [0, 1 , 2, 3]\n",
    "row_title = label_list = [str(i) for i in range(3+1)]\n",
    "matrix = confusion_matrix(predict, test_y, 3)\n",
    "print(matrix)\n",
    "df = pd.DataFrame.from_records(data=matrix, index =row_title)\n",
    "print(df)\n",
    "# print(col_title)\n",
    "# print(confusion_matrix(predict, test_y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5, 5])\n",
    "print(arr)\n",
    "idx = np.argpartition(arr, 3)[:3]\n",
    "print(arr[idx])\n",
    "o = np.zeros((1, 6))\n",
    "for i in range(6):\n",
    "    o[0][i] = np.sum(arr==i)\n",
    "print(o[0])\n",
    "predict = np.max(o[0])\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex1.1 data\n",
    "train_x = np.array([[0.376000, 0.488000],\n",
    "                  [0.312000, 0.544000],\n",
    "                  [0.298000, 0.624000],\n",
    "                  [0.394000, 0.600000],\n",
    "                  [0.506000, 0.512000],\n",
    "                  [0.488000, 0.334000],\n",
    "                  [0.478000, 0.398000],\n",
    "                  [0.606000, 0.366000],\n",
    "                  [0.428000, 0.294000],\n",
    "                  [0.542000, 0.252000]]\n",
    "                  )\n",
    "train_y = np.array([[0], [0], [0], [0], [0], [1], [1], [1], [1], [1]])\n",
    "\n",
    "test_x = np.array([[0.550000, 0.364000],\n",
    "                  [0.558000, 0.470000],\n",
    "                  [0.456000, 0.450000],\n",
    "                  [0.450000, 0.570000]]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-particular",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
